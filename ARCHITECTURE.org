* Development process

Project's main build system is written in python and uses the =invoke= library to manage tasks and dependencies between them. Inside, there are two cmake configurations that are intended to be self-contained, e.g., one should be able to compile the whole thing without running any code generation components. Just check out submodules and build the C++ code. At least that is the intention, implementation is not quite there yet (see [[id:2e97816d-eb26-463c-9a9b-db60b15fdc55][Where?]]).

* Sub-projects

** Lexer configuration

To read the base text file into stream of tokens haxorg uses [[https://github.com/Genivia/RE-flex][re/flex lexer]] which handles all the low-level details of the string buffering and regex rule recognition for the maximum efficiency.

The lexer grammar is described in ~src/base_lexer/base_lexer.yaml~ -- it is designed to be as light on imperative logic as

** Code generation

** Reflection data collection

Automatically wrapping all C++ code in =pybind11= wrappers is too time-consuming. It is more efficient to use =libtooling= API to collect all the required information about the types, methods, typedefs, enums and other things and automatically generate the wrappers.

** Main org-mode parser

** Test corpus verification

Collection of yaml files with a smaller pieces of code and expected tokens, parsed trees and sem converted trees. This is main part of the test suite for checking if the implementation is working as expected.

** Standard library helpers

** Code forensics

This is a script largely unrelated to the org-mode processing itself, an implementation of [[https://www.amazon.com/Your-Code-Crime-Scene-Bottlenecks/dp/1680500384][Code Forensics]] book. A smaller side project I put here because it uses the stdlib helpers and pretty much all of the other infrastructure I set up. Would be too much work to maintain it independently.

* Code novelties

** TODO How reflection is used in this project

** TODO Extended stdlib

* Testing infrastructure

The test suite for the project is split into four parts: support 'std'lib components, org-mode document corpus, python logic tests and extra side projects.

** Document corpus

The most important part of the testing suite -- collection of ~.yaml~ files that contains a series of example documents to be verified.

#+begin_src yaml
items:
  - name: "Source block without language name"
    source: |
      #+begin_src
      cd 1
      #+end_src
#+end_src

Each test has ~source:~ field with the content of the standalone document. Verification logic compares intermediate results of the test with given expectations -- base tokens, converted tokens, parsed tree or sem tree. Unless disabled, each document is processed twice.

- Process document into base lexer tokens
- Recombine the base tokens into groups -- adding indentation, wrapping paragraphs and statement lists, dropping or adding the tokens to normalize stream of data
- Parse the recombined token stream into the parsed tree
- Convert parsed tree into sem tree
- If all parts are ok -- format the sem tree back to source and re-run the whole sequence on the new document and then compare sem tree 1 vs sem tree 2

Each part of the document spec can have expected constraints:

#+caption: Expected base and converted tokens
#+begin_src yaml
    base_tokens:
      - {kind: SubtreeStars, str: "*"}
      - {kind: Whitespace, str: " "}
      - {kind: Word, str: Subtree}
      - {kind: EndOfFile, str: ""}

    tokens:
      - {kind: SubtreeStars, str: "*"}
      - {kind: Whitespace, str: " "}
      - {kind: Word, str: "Subtree"}
#+end_src

Parsed tree structure,

#+caption: Flat representation of the parsed tree
#+begin_src yaml
    subnodes:
      - {kind: StmtList, extent: 3}
      - {kind: Paragraph, extent: 2}
      - {kind: Bold, extent: 1}
      - {kind: Word, tok_idx: 1, str: "bold"}
#+end_src

Or expected sem tree

#+caption: Full document for parsed symbol
#+begin_src yaml
    sem:
      kind: Document
      subnodes:
        - kind: Paragraph
          subnodes:
            - kind: Symbol
              name: "symbol"
              parameters: []
              positional: [{kind: Empty}]
#+end_src

** TODO Debugging tests
